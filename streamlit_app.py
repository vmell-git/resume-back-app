# app.py
# ------------------------------------------------------
# Streamlit ‚Äì G√©n√©rateur d'Excel r√©capitulatif de param√©trage Hopia
# Entr√©es possibles :
#   - Fichier brut (TXT / CSV / XLSX) de type "export Excel"
#   - Copier-coller de texte brut (y compris format vertical type Urgentistes)
# ------------------------------------------------------

import io
import re
from typing import Tuple

import pandas as pd
import streamlit as st

# ------------------------------------------------------
# Configuration Streamlit
# ------------------------------------------------------
st.set_page_config(page_title="Hopia ‚Äì R√©cap Param√©trage", layout="wide")

st.title("üìä Hopia ‚Äì G√©n√©rateur d‚ÄôExcel r√©capitulatif de param√©trage")

# ------------------------------------------------------
# Couleurs pour l'export Excel
# ------------------------------------------------------
COLOR_DURE = "#ffcccc"        # rouge clair
COLOR_MOY = "#ffe5b4"         # orange clair
COLOR_SOFT = "#ccffcc"        # vert clair
COLOR_HEADER = "#003366"      # bleu fonc√©
COLOR_HEADER_TXT = "#FFFFFF"  # texte header blanc


# ------------------------------------------------------
# Parseur pour le format vertical (exemple Urgentistes)
# ------------------------------------------------------
def parse_vertical_blocks(content: str) -> pd.DataFrame:
    """
    Parse un texte copi√©-coll√© au format :
    PK
    Intitul√© [TAB ou 2+ espaces] Type
    (une ou plusieurs lignes de Priorit√©s)
    √âquipes

    Exemple concret : le gros bloc 'Urgentistes' fourni.
    """
    lines = [l.strip() for l in content.splitlines()]
    # On enl√®ve les lignes vides
    lines = [l for l in lines if l]

    # On avance jusqu'√† la premi√®re ligne qui ressemble √† un PK num√©rique
    i = 0
    while i < len(lines) and not lines[i].isdigit():
        i += 1

    def looks_like_pk(s: str) -> bool:
        return s.isdigit()

    def looks_like_priority(s: str) -> bool:
        # Tout ce qui ressemble √† une in√©galit√© ou un token de p√©nalit√©
        return bool(
            re.search(
                r"(HARD(?:_LOWER)?|SOFT_\d|STRONG_\d|PRIORITY_\d|DEFAULT_PENALTY|PRIVATE_ALGO_1|<|>|‚â§|>=|‚â•)",
                s
            )
        )

    records = []

    while i < len(lines):
        if not looks_like_pk(lines[i]):
            # Si on tombe sur autre chose qu'un PK, on avance
            i += 1
            continue

        pk = lines[i]
        i += 1
        if i >= len(lines):
            break

        # Ligne suivante : Intitul√© + Type s√©par√©s par tab ou au moins 2 espaces
        line2 = lines[i]
        i += 1

        parts = re.split(r"\t+| {2,}", line2, maxsplit=1)
        if len(parts) == 2:
            intitule = parts[0].strip()
            type_val = parts[1].strip()
        else:
            intitule = parts[0].strip()
            type_val = ""

        # On accumule les lignes de Priorit√©s, puis l'√âquipe
        prio_lines: list[str] = []
        equipe = ""

        while i < len(lines) and not looks_like_pk(lines[i]):
            l = lines[i]

            # Si on a d√©j√† des priorit√©s et que la ligne ne ressemble plus √† une priorit√© ‚Üí √©quipe
            if not looks_like_priority(l) and prio_lines:
                equipe = l
                i += 1
                break

            # Si aucune priorit√© lue et la ligne ne ressemble pas √† une priorit√© :
            # on consid√®re que c'est une ligne "√âquipes" sans priorit√©s d√©taill√©es.
            if not looks_like_priority(l) and not prio_lines:
                equipe = l
                i += 1
                break

            # Sinon, c'est une ligne de priorit√©s
            prio_lines.append(l)
            i += 1

        priorite = " ".join(prio_lines).strip()

        records.append(
            {
                "PK": pk,
                "Intitul√©": intitule,
                "Type": type_val,
                "Priorit√©s": priorite,
                "√âquipes": equipe,
            }
        )

    if not records:
        return pd.DataFrame()

    return pd.DataFrame(records)


# ------------------------------------------------------
# Lecture de contenu texte brut (copier-coller)
# ------------------------------------------------------
def read_text_content(content: str) -> pd.DataFrame | None:
    """
    Lit un contenu texte brut :
    1) On tente le format vertical (type Urgentistes)
    2) Sinon on tente des formats CSV/TSV classiques
    """
    content = content.strip()
    if not content:
        return None

    # 1) Tentative : format vertical
    df_vert = parse_vertical_blocks(content)
    if not df_vert.empty:
        return df_vert

    # 2) Tentative : CSV classique (s√©parateurs ; tab ,)
    possible_seps = [";", "\t", ","]
    for sep in possible_seps:
        try:
            df = pd.read_csv(io.StringIO(content), sep=sep, engine="python")
            if df.shape[1] >= 2:
                return df
        except Exception:
            pass

    # 3) Dernier recours : s√©paration par espaces
    try:
        df = pd.read_csv(io.StringIO(content), delim_whitespace=True, engine="python")
        return df
    except Exception:
        st.error("Impossible d'interpr√©ter le texte coll√©. V√©rifie le format.")
        return None


# ------------------------------------------------------
# Lecture du fichier upload√© (TXT / CSV / XLSX)
# ------------------------------------------------------
def read_uploaded_file(uploaded_file) -> pd.DataFrame | None:
    """Lit le fichier upload√©, en g√©rant TXT, CSV, XLSX, avec d√©tection auto du s√©parateur pour le texte."""
    name = uploaded_file.name.lower()

    if name.endswith((".xlsx", ".xls")):
        return pd.read_excel(uploaded_file)

    # CSV classique
    if name.endswith(".csv"):
        # sep=None + engine="python" ‚Üí d√©tection automatique du s√©parateur
        return pd.read_csv(uploaded_file, sep=None, engine="python")

    # Fichier texte brut
    if name.endswith(".txt"):
        raw_bytes = uploaded_file.read()
        try:
            content = raw_bytes.decode("utf-8")
        except UnicodeDecodeError:
            content = raw_bytes.decode("latin-1")

        return read_text_content(content)

    st.error("Format de fichier non support√©. Utilise un .txt, .csv ou .xlsx.")
    return None


# ------------------------------------------------------
# Normalisation des colonnes
# ------------------------------------------------------
def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    """
    - Harmonise les noms de colonnes (strip)
    - S'assure que PK, Type, Priorit√©s, √âquipes existent
    - Cr√©e 'Intitul√©' si absent (copie de Type pour la lisibilit√©)
    """
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    # Colonnes obligatoires minimales
    needed = ["PK", "Type", "Priorit√©s", "√âquipes"]
    for col in needed:
        if col not in df.columns:
            df[col] = None

    # Intitul√© : si absent, on duplique Type pour avoir un libell√© lisible
    if "Intitul√©" not in df.columns:
        df["Intitul√©"] = df["Type"]

    # Ordre des colonnes (les autres suivront)
    front = ["PK", "Intitul√©", "Type", "Priorit√©s", "√âquipes"]
    front_existing = [c for c in front if c in df.columns]
    others = [c for c in df.columns if c not in front_existing]

    return df[front_existing + others]


# ------------------------------------------------------
# Analyse des tokens de priorit√©
# ------------------------------------------------------
def token_set(priorites: str) -> set:
    """Extrait les tokens de p√©nalit√©s/forces (HARD, SOFT_1, PRIORITY_1, etc.) d'une cha√Æne."""
    if pd.isna(priorites):
        return set()
    txt = str(priorites).upper()

    # On capture les mots-cl√©s m√™me dans des expressions du type
    # "2 < SOFT_2 ‚â§ 3 3 < PRIORITY_1 ‚â§ 4"
    parts = re.findall(
        r"(HARD(?:_LOWER)?|SOFT_\d|STRONG_\d|PRIORITY_\d|DEFAULT_PENALTY|PRIVATE_ALGO_1)",
        txt
    )
    return set(parts)


# ------------------------------------------------------
# Mapping vers DURE / MOYENNE / SOUPLE
# ------------------------------------------------------
def map_level(row) -> Tuple[str, str]:
    """
    Retourne (Niveau, R√®gle utilis√©e) en fonction de :
    - Type de contrainte (Remplissage des postes ou non)
    - Priorit√©s (HARD, SOFT_x, PRIORITY_x, STRONG_x, HARD_LOWER, DEFAULT_PENALTY)
    """
    type_txt = str(row.get("Type", "")).strip().lower()
    prio_raw = str(row.get("Priorit√©s", ""))
    toks = token_set(prio_raw)

    is_remplissage = "remplissage des postes" in type_txt

    # Valeur par d√©faut si on ne comprend rien ‚Üí SOUPLE
    niveau = "SOUPLE"
    rule = "SOFT_* ‚Üí SOUPLE (fallback)"

    if is_remplissage:
        # Cas particulier des postes √† remplir
        if {"PRIORITY_1", "HARD", "STRONG_1"} & toks:
            return "DURE", "Remplissage : PRIORITY_1/HARD/STRONG_1 ‚Üí DURE"
        if {"PRIORITY_2", "STRONG_2", "STRONG_3"} & toks:
            return "MOYENNE", "Remplissage : PRIORITY_2/STRONG_2/STRONG_3 ‚Üí MOYENNE"
        if (
            {"PRIORITY_3", "DEFAULT_PENALTY"} & toks
            or any(t.startswith("SOFT_") for t in toks)
        ):
            return "SOUPLE", "Remplissage : PRIORITY_3/DEFAULT_PENALTY/SOFT_* ‚Üí SOUPLE"
        # Aucun token connu : on laisse SOUPLE
        return niveau, rule

    # Cas g√©n√©ral (hors Remplissage des postes)
    if "HARD" in toks or "HARD_LOWER" in toks:
        return "DURE", "Hors remplissage : HARD/HARD_LOWER ‚Üí DURE"
    if (
        any(t.startswith("STRONG_") for t in toks)
        or any(t.startswith("PRIORITY_") for t in toks)
        or "DEFAULT_PENALTY" in toks
        or "PRIVATE_ALGO_1" in toks
    ):
        return "MOYENNE", "Hors remplissage : STRONG_*/PRIORITY_*/DEFAULT/PRIVATE ‚Üí MOYENNE"
    if any(t.startswith("SOFT_") for t in toks):
        return "SOUPLE", "Hors remplissage : SOFT_* ‚Üí SOUPLE"

    # Aucun mot-cl√© reconnu : on laisse SOUPLE
    return niveau, rule


def color_for_level(level: str) -> str:
    """Renvoie la couleur hex correspondante au niveau (DURE/MOYENNE/SOUPLE)."""
    l = (level or "").upper().replace("√â", "E")
    if "DURE" in l:
        return COLOR_DURE
    if "MOY" in l:  # MOYENNE
        return COLOR_MOY
    return COLOR_SOFT


# ------------------------------------------------------
# R√©sum√© par rubrique (Type)
# ------------------------------------------------------
def build_summary(df: pd.DataFrame) -> pd.DataFrame:
    tmp = df.copy()
    tmp["Niveau"] = tmp["Niveau"].fillna("SOUPLE")

    piv = pd.pivot_table(
        tmp,
        index="Type",
        columns="Niveau",
        values="PK",
        aggfunc="count",
        fill_value=0
    )

    # On force l‚Äôordre des colonnes
    piv = piv.reindex(columns=["DURE", "MOYENNE", "SOUPLE"], fill_value=0)
    piv["Total"] = piv.sum(axis=1)
    piv = piv.reset_index().rename(columns={"Type": "Rubrique"})

    return piv


# ------------------------------------------------------
# Construction du fichier Excel
# (df_autres / df_remp = seulement Intitul√© / Type / Equipe / Niveau)
# ------------------------------------------------------
def to_excel_bytes(df_summary: pd.DataFrame,
                   df_autres: pd.DataFrame,
                   df_remp: pd.DataFrame) -> bytes:
    import xlsxwriter  # utilis√© par pandas.ExcelWriter(engine='xlsxwriter')

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        wb = writer.book

        # -------- Feuille 1 ‚Äì R√©sum√© par rubrique --------
        df_summary.to_excel(writer, sheet_name="R√©sum√© par rubrique", index=False)
        ws = writer.sheets["R√©sum√© par rubrique"]

        fmt_header = wb.add_format(
            {
                "bold": True,
                "bg_color": COLOR_HEADER,
                "font_color": COLOR_HEADER_TXT,
                "align": "center",
            }
        )

        # Largeur + header
        for col_idx, col_name in enumerate(df_summary.columns):
            ws.write(0, col_idx, col_name, fmt_header)
            ws.set_column(col_idx, col_idx, 25)

        # Coloration des colonnes par niveau
        col_map = {"DURE": COLOR_DURE, "MOYENNE": COLOR_MOY, "SOUPLE": COLOR_SOFT}
        for col_name, bg in col_map.items():
            if col_name in df_summary.columns:
                col_idx = df_summary.columns.get_loc(col_name)
                fmt_lvl = wb.add_format({"bg_color": bg})
                ws.conditional_format(
                    1,
                    col_idx,
                    len(df_summary) + 50,
                    col_idx,
                    {"type": "no_errors", "format": fmt_lvl},
                )

        # -------- Feuille 2 ‚Äì Autres contraintes --------
        df_autres.to_excel(writer, sheet_name="Param√©trage ‚Äì Autres", index=False)
        ws2 = writer.sheets["Param√©trage ‚Äì Autres"]

        for col_idx, col_name in enumerate(df_autres.columns):
            ws2.write(0, col_idx, col_name, fmt_header)
            ws2.set_column(col_idx, col_idx, 28)

        if "Niveau" in df_autres.columns:
            for row_idx in range(1, len(df_autres) + 1):
                level = str(df_autres.iloc[row_idx - 1]["Niveau"])
                bg = color_for_level(level)
                fmt_row = wb.add_format({"bg_color": bg})
                ws2.set_row(row_idx, None, fmt_row)

        # -------- Feuille 3 ‚Äì Remplissage des postes --------
        df_remp.to_excel(writer, sheet_name="Param√©trage ‚Äì Remplissage", index=False)
        ws3 = writer.sheets["Param√©trage ‚Äì Remplissage"]

        for col_idx, col_name in enumerate(df_remp.columns):
            ws3.write(0, col_idx, col_name, fmt_header)
            ws3.set_column(col_idx, col_idx, 28)

        if "Niveau" in df_remp.columns:
            for row_idx in range(1, len(df_remp) + 1):
                level = str(df_remp.iloc[row_idx - 1]["Niveau"])
                bg = color_for_level(level)
                fmt_row = wb.add_format({"bg_color": bg})
                ws3.set_row(row_idx, None, fmt_row)

    return output.getvalue()


# ------------------------------------------------------
# Interface ‚Äì Upload OU copier-coller
# ------------------------------------------------------
uploaded = st.file_uploader(
    "üìÅ Importer un fichier texte ou Excel de param√©trage",
    type=["txt", "csv", "xlsx", "xls"],
)

text_pasted = st.text_area(
    "‚úÇÔ∏è Ou collez directement ici le contenu de votre export :",
    placeholder="PK\tType\tPriorit√©s\t√âquipes\n549\tPas de MAO...\n...",
    height=200,
)

df_raw = None

if uploaded is not None:
    df_raw = read_uploaded_file(uploaded)
elif text_pasted.strip():
    df_raw = read_text_content(text_pasted)

with st.expander("üîç Exemple de structure attendue (mini)"):
    example_df = pd.DataFrame(
        {
            "PK": [1536, 1692, 1767],
            "Type": [
                "OS4 - Jeudi MAT CS",
                "Pas d'affectation sur Jour OFF",
                "Remplissage des postes Bloc",
            ],
            "Priorit√©s": ["HARD", "HARD", "PRIORITY_2"],
            "√âquipes": ["ARE", "ARE", "ARE"],
        }
    )
    st.dataframe(example_df, use_container_width=True)

if df_raw is not None:
    try:
        df_norm = normalize_cols(df_raw)

        # Calcul Niveau + R√®gle
        levels = df_norm.apply(map_level, axis=1, result_type="expand")
        df_norm["Niveau"] = levels[0]
        df_norm["R√®gle de mapping"] = levels[1]

        # üîπ Filtrage : on enl√®ve Demandes d'absence / Demandes de travail
        mask = ~df_norm["Type"].astype(str).str.strip().isin(
            ["Demandes d'absence", "Demandes de travail"]
        )
        df_filtered = df_norm[mask].copy()

        # R√©sum√© (sur le df filtr√©, on garde PK pour le pivot)
        df_summary = build_summary(df_filtered)

        # üîπ DataFrames pour export : seulement Intitul√© / Type / Equipe / Niveau
        df_filtered["Equipe"] = df_filtered["√âquipes"]

        is_remplissage = df_filtered["Type"].astype(str).str.strip().str.lower() == "remplissage des postes"

        df_autres = df_filtered[~is_remplissage][["Intitul√©", "Type", "Equipe", "Niveau"]].copy()
        df_remp = df_filtered[is_remplissage][["Intitul√©", "Type", "Equipe", "Niveau"]].copy()

        st.success("‚úÖ Donn√©es charg√©es, filtr√©es et interpr√©t√©es avec succ√®s.")

        with st.expander("Aper√ßu ‚Äì Autres contraintes (export√©es)"):
            st.dataframe(df_autres.head(50), use_container_width=True)

        with st.expander("Aper√ßu ‚Äì Remplissage des postes (export√©es)"):
            st.dataframe(df_remp.head(50), use_container_width=True)

        with st.expander("Aper√ßu ‚Äì R√©sum√© par rubrique"):
            st.dataframe(df_summary, use_container_width=True)

        # Export Excel
        excel_bytes = to_excel_bytes(df_summary, df_autres, df_remp)
        st.download_button(
            "‚¨áÔ∏è T√©l√©charger l'Excel r√©capitulatif harmonis√©",
            data=excel_bytes,
            file_name="Parametrage_Harmonise.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        st.markdown("### üîé Rappels de mapping (m√©mo)")
        st.markdown(
            """
**Hors _Remplissage des postes_ :**

- `HARD` / `HARD_LOWER` ‚Üí **DURE**
- `STRONG_*` / `PRIORITY_*` / `DEFAULT_PENALTY` / `PRIVATE_ALGO_1` ‚Üí **MOYENNE**
- `SOFT_*` ‚Üí **SOUPLE**

**Pour _Remplissage des postes_ :**

- `PRIORITY_1` / `HARD` / `STRONG_1` ‚Üí **DURE** (poste √† remplir en priorit√© extr√™me)
- `PRIORITY_2` / `STRONG_2` / `STRONG_3` ‚Üí **MOYENNE** (poste √† remplir normalement)
- `PRIORITY_3` / `DEFAULT_PENALTY` / `SOFT_*` ‚Üí **SOUPLE** (poste √† remplir en dernier)
"""
        )

    except Exception as e:
        st.error(f"Erreur lors du traitement des donn√©es : {e}")
else:
    st.info("Importe un fichier **ou** colle le contenu de ton export pour g√©n√©rer l‚ÄôExcel harmonis√©.")
